# 4.3 Creación de Tabla de tokens

Después de que el analizador léxico ha identificado los tokens en el código fuente, se procede a almacenarlos en una tabla de tokens. Esta tabla contiene la siguiente información:

## Tipo de token

* Cada entrada en la tabla de tokens incluye el tipo de token al que pertenece el lexema identificado. Esto puede ser una palabra clave, un identificador, un número, un operador, etc. Esta clasificación es esencial para el análisis posterior del código.

## Lexema

* El lexema es la secuencia de caracteres que forma el token. En la tabla de tokens, se registra el lexema correspondiente a cada token identificado. Esta información es crucial para mantener la integridad y la representación precisa de los componentes léxicos.

## Posición en el código fuente

* Se registra la posición del token en el código fuente. Esta información ayuda a rastrear la ubicación exacta de cada token, lo que puede ser útil para informar errores o para el análisis semántico posterior.

## Información adicional

* Además del tipo de token y el lexema, la tabla de tokens puede contener información adicional relevante para cada token. Por ejemplo, el valor numérico de un número, la longitud de una cadena de texto, u otros detalles específicos que puedan ser necesarios para el análisis posterior.

## Paso al analizador sintáctico

* Una vez que la tabla de tokens se ha creado y poblado con la información necesaria, se pasa al analizador sintáctico como entrada para el siguiente paso del proceso de compilación. El analizador sintáctico utilizará esta tabla para construir la estructura gramatical del programa.

En resumen, la creación de una tabla de tokens en un analizador léxico es un paso fundamental que organiza y almacena la información clave sobre los tokens identificados en el código fuente. Esta tabla proporciona los datos necesarios para el análisis sintáctico y otros procesos posteriores en el proceso de compilación del programa.
